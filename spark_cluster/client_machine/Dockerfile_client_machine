FROM coffeeblast/hadoop_single_node_cluster_img:latest

SHELL ["/bin/bash", "-c"]
# installing linux packages
RUN apt-get update && apt-get upgrade && apt-get install -y python3 python3-pip
RUN PYSPARK_HADOOP_VERSION=without pip3 install pyspark -v
RUN mkdir /spark_conf
COPY ./scripts/admin /scripts/admin/client_machine
COPY --from=spark ./conf/spark-env.sh /spark_conf/spark-env.sh
RUN chmod u+x /spark_conf/spark-env.sh /scripts/admin/client_machine/startup.sh
RUN echo "source /spark_conf/spark-env.sh" >> /root/.bashrc